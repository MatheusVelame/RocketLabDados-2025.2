{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a94d0a10-dfdc-40c7-aeb3-68774e8b9b3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Configuração do Ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbdc0b6a-2556-40f2-8989-e290e9624093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Configura o catálogo e o esquema, conectando o notebook às camadas bronze (leitura) e silver (escrita)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8fee287-2c81-474d-ab50-65f31cbf0fb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuração OK. Lendo de bronze e escrevendo em silver.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Variáveis de ambiente\n",
    "CATALOG_NAME = \"`workspace`\" \n",
    "SCHEMA_NAME = \"olist_ecommerce\"\n",
    "\n",
    "# Configuração da sessão no Unity Catalog\n",
    "spark.sql(f\"USE CATALOG {CATALOG_NAME}\")\n",
    "spark.sql(f\"USE SCHEMA {SCHEMA_NAME}\")\n",
    "\n",
    "print(f\"✅ Configuração OK. Lendo de bronze e escrevendo em silver.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ff9bd9e-497f-4f37-b13a-f61ad466cdf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# silver.ft_consumidores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87a1bd59-764d-437b-ab72-a8a27144263b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Implementa a renomeação, padronização para Upper Case na cidade/estado, e a remoção de duplicatas no id_consumidor ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59a722a5-842e-4ab8-8741-f3c44c5b7207",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela Silver 'silver.ft_consumidores' criada/atualizada com sucesso.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, upper\n",
    "\n",
    "source_table = \"bronze.ft_consumidores\"\n",
    "target_table = \"silver.ft_consumidores\"\n",
    "\n",
    "df_bronze = spark.read.table(source_table)\n",
    "\n",
    "# Seleção, Renomeação e Upper Case\n",
    "df_silver = (df_bronze\n",
    "    .select(\n",
    "        col(\"customer_id\").alias(\"id_consumidor\"), \n",
    "        col(\"customer_zip_code_prefix\").alias(\"prefixo_cep\"), \n",
    "        upper(col(\"customer_city\")).alias(\"cidade\"), \n",
    "        upper(col(\"customer_state\")).alias(\"estado\"), \n",
    "        col(\"ingestion_timestamp\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Verificação e Remoção de Duplicados em 'id_consumidor' \n",
    "initial_count = df_silver.count()\n",
    "df_final = df_silver.dropDuplicates([\"id_consumidor\"]) \n",
    "removed_count = initial_count - df_final.count()\n",
    "\n",
    "if removed_count > 0:\n",
    "    print(f\"⚠️ Alerta: {removed_count} IDs de consumidores duplicados foram removidos.\")\n",
    "\n",
    "# Salvar na Camada Silver\n",
    "(df_final.write\n",
    "    .mode(\"overwrite\")\n",
    "    .format(\"delta\")\n",
    "    .saveAsTable(target_table))\n",
    "\n",
    "print(f\"✅ Tabela Silver '{target_table}' criada/atualizada com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4825c10e-6926-46de-86e9-5ea6ce455262",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# silver.ft_pedidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a6f3dc0-ff5a-47ef-a8aa-80877eb0f96a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Implementa a tradução do order_status e a criação das 4 colunas derivadas de tempo/entrega ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36e0fbcc-bc5f-4b65-95c3-817a99b6aa7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela Silver 'silver.ft_pedidos' criada/atualizada com sucesso.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, datediff, lit, when, to_timestamp\n",
    "\n",
    "source_table = \"bronze.ft_pedidos\"\n",
    "target_table = \"silver.ft_pedidos\"\n",
    "\n",
    "df_bronze = spark.read.table(source_table)\n",
    "\n",
    "# Mapeamento de Status (Inglês -> Português) \n",
    "status_map = {\n",
    "    \"delivered\": \"entregue\", \"invoiced\": \"faturado\", \"shipped\": \"enviado\",\n",
    "    \"processing\": \"em processamento\", \"unavailable\": \"indisponível\", \"canceled\": \"cancelado\",\n",
    "    \"created\": \"criado\", \"approved\": \"aprovado\"\n",
    "} \n",
    "\n",
    "# Cria a expressão CASE WHEN encadeada\n",
    "status_expr = col(\"order_status\")\n",
    "for k, v in status_map.items():\n",
    "    status_expr = when(col(\"order_status\") == k, lit(v)).otherwise(status_expr)\n",
    "\n",
    "# Renomeação e Tipagem\n",
    "df_temp = (df_bronze\n",
    "    .select(\n",
    "        col(\"order_id\").alias(\"id_pedido\"), col(\"customer_id\").alias(\"id_consumidor\"),\n",
    "        status_expr.alias(\"status\"),\n",
    "        to_timestamp(\"order_purchase_timestamp\").alias(\"pedido_compra_timestamp\"),\n",
    "        to_timestamp(\"order_delivered_customer_date\").alias(\"pedido_entregue_timestamp\"),\n",
    "        to_timestamp(\"order_estimated_delivery_date\").alias(\"pedido_estimativa_entrega_timestamp\"),\n",
    "        to_timestamp(\"order_approved_at\").alias(\"pedido_aprovado_timestamp\"),\n",
    "        to_timestamp(\"order_delivered_carrier_date\").alias(\"pedido_carregado_timestamp\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Criação das Colunas Derivadas (Tempo em Dias)\n",
    "df_silver = (df_temp\n",
    "    .withColumn(\"tempo_entrega_dias\", \n",
    "        datediff(col(\"pedido_entregue_timestamp\"), col(\"pedido_compra_timestamp\")) \n",
    "    )\n",
    "    .withColumn(\"tempo_entrega_estimado_dias\", \n",
    "        datediff(col(\"pedido_estimativa_entrega_timestamp\"), col(\"pedido_compra_timestamp\")) \n",
    "    )\n",
    "    .withColumn(\"diferenca_entrega_dias\", \n",
    "        col(\"tempo_entrega_dias\") - col(\"tempo_entrega_estimado_dias\") \n",
    "    )\n",
    "    .withColumn(\"entrega_no_prazo\",\n",
    "        when(col(\"status\") != \"entregue\", lit(\"Não Entregue\")) \n",
    "        .when(col(\"diferenca_entrega_dias\") <= 0, lit(\"Sim\")) \n",
    "        .otherwise(lit(\"Não\")) \n",
    "    )\n",
    ")\n",
    "\n",
    "# Salvar na Camada Silver\n",
    "(df_silver.write\n",
    "    .mode(\"overwrite\")\n",
    "    .format(\"delta\")\n",
    "    .saveAsTable(target_table))\n",
    "\n",
    "print(f\"✅ Tabela Silver '{target_table}' criada/atualizada com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43afe21c-c8cf-4a3c-b1de-1131f3da1e3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# silver.ft_pagamentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e818cb30-d90a-4931-b8b6-80b8a22b0a8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Implementa a tradução do tipo de pagamento e o casting para DECIMAL(12,2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5d756a6-52b1-4be4-a4c2-5a12d3aac951",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela Silver 'silver.ft_pagamentos' criada/atualizada com sucesso.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, lit\n",
    "\n",
    "source_table = \"bronze.ft_pagamentos_pedidos\"\n",
    "target_table = \"silver.ft_pagamentos\"\n",
    "\n",
    "df_bronze = spark.read.table(source_table)\n",
    "\n",
    "# Mapeamento de Forma de Pagamento (Inglês -> Português) \n",
    "payment_expr = when(col(\"payment_type\") == \"credit_card\", lit(\"Cartão de Crédito\"))\n",
    "payment_expr = payment_expr.when(col(\"payment_type\") == \"boleto\", lit(\"Boleto\"))\n",
    "payment_expr = payment_expr.when(col(\"payment_type\") == \"voucher\", lit(\"Voucher\"))\n",
    "payment_expr = payment_expr.when(col(\"payment_type\") == \"debit_card\", lit(\"Cartão de Débito\"))\n",
    "payment_expr = payment_expr.otherwise(lit(\"Outro\")) \n",
    "\n",
    "# Seleção, Renomeação e Conversão de Tipos\n",
    "df_silver = (df_bronze\n",
    "    .select(\n",
    "        col(\"order_id\").alias(\"id_pedido\"), \n",
    "        col(\"payment_sequential\").alias(\"codigo_pagamento\"), \n",
    "        payment_expr.alias(\"forma_pagamento\"),\n",
    "        col(\"payment_installments\").alias(\"parcelas\"), \n",
    "        col(\"payment_value\").cast(\"DECIMAL(12,2)\").alias(\"valor_pagamento\"), \n",
    "        col(\"ingestion_timestamp\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Salvar na Camada Silver\n",
    "(df_silver.write\n",
    "    .mode(\"overwrite\")\n",
    "    .format(\"delta\")\n",
    "    .saveAsTable(target_table))\n",
    "\n",
    "print(f\"✅ Tabela Silver '{target_table}' criada/atualizada com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7171f47-1e57-4f6e-902a-54c5c4085d8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Transformações Simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a1bd39c-6d3e-4816-b061-79233f75aec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Usa uma função genérica para aplicar renomeação, casting e Upper Case a múltiplas tabelas, incluindo a tabela ft_itens_pedidos que estava faltando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "626e3938-706e-4689-8fb0-e9858f8c2bd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando transformações simples (ft_itens_pedidos, ft_vendedores, ft_produtos, dm_categoria_produtos_traducao)...\n  > ✅ Tabela Silver 'silver.ft_itens_pedidos' criada/atualizada com sucesso.\n  > ✅ Tabela Silver 'silver.ft_vendedores' criada/atualizada com sucesso.\n  > ✅ Tabela Silver 'silver.ft_produtos' criada/atualizada com sucesso.\n  > ✅ Tabela Silver 'silver.dm_categoria_produtos_traducao' criada/atualizada com sucesso.\n✅ Transformações simples concluídas.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, upper, lit\n",
    "from pyspark.sql.types import DecimalType\n",
    "\n",
    "\n",
    "# Função genérica de funcionamento\n",
    "def transform_and_save_simple_final(bronze_table_name, target_map):\n",
    "    \"\"\"Lê do Bronze, aplica mapeamento, tipagem e Upper Case, e salva no Silver.\"\"\"\n",
    "    \n",
    "    source_table = f\"bronze.{bronze_table_name}\"\n",
    "    target_table = f\"silver.{bronze_table_name}\"\n",
    "    \n",
    "    df_bronze = spark.read.table(source_table)\n",
    "    select_cols = []\n",
    "    \n",
    "    for col_b, col_s, dtype, is_upper in target_map:\n",
    "        expr = col(col_b)\n",
    "        \n",
    "        if is_upper:\n",
    "            expr = upper(col(col_b))\n",
    "\n",
    "        expr = expr.cast(dtype)\n",
    "            \n",
    "        select_cols.append(expr.alias(col_s))\n",
    "        \n",
    "    select_cols.append(col(\"ingestion_timestamp\"))\n",
    "    \n",
    "    df_silver = df_bronze.select(*select_cols)\n",
    "    \n",
    "    # Salva como Delta Lake\n",
    "    (df_silver.write\n",
    "     .mode(\"overwrite\")\n",
    "     .format(\"delta\")\n",
    "     .option(\"mergeSchema\", \"true\") \n",
    "     .saveAsTable(target_table))\n",
    "\n",
    "    print(f\"  > ✅ Tabela Silver '{target_table}' criada/atualizada com sucesso.\")\n",
    "\n",
    "# Mapa de configuração centralizado\n",
    "TRANSFORM_MAP = {\n",
    "    # ft_itens_pedidos (Etapa 3)\n",
    "    \"ft_itens_pedidos\": [\n",
    "        (\"order_id\", \"id_pedido\", \"STRING\", False),\n",
    "        (\"order_item_id\", \"id_item\", \"INT\", False),\n",
    "        (\"product_id\", \"id_produto\", \"STRING\", False),\n",
    "        (\"seller_id\", \"id_vendedor\", \"STRING\", False),\n",
    "        (\"price\", \"preco_BRL\", DecimalType(12, 2), False), \n",
    "        (\"freight_value\", \"preco_frete\", DecimalType(12, 2), False), \n",
    "    ],\n",
    "    # ft_vendedores (Etapa 7) \n",
    "    \"ft_vendedores\": [\n",
    "        (\"seller_id\", \"id_vendedor\", \"STRING\", False),\n",
    "        (\"seller_zip_code_prefix\", \"prefixo_cep\", \"INT\", False), \n",
    "        (\"seller_city\", \"cidade\", \"STRING\", True), \n",
    "        (\"seller_state\", \"estado\", \"STRING\", True), \n",
    "    ],\n",
    "    # ft_produtos (Etapa 6) \n",
    "    \"ft_produtos\": [\n",
    "        (\"product_id\", \"id_produto\", \"STRING\", False),\n",
    "        (\"product_category_name\", \"categoria_produto\", \"STRING\", False),\n",
    "        (\"product_weight_g\", \"peso_produto_gramas\", \"INT\", False),\n",
    "        (\"product_length_cm\", \"comprimento_centimetros\", \"INT\", False),\n",
    "        (\"product_height_cm\", \"altura_centimetros\", \"INT\", False),\n",
    "        (\"product_width_cm\", \"largura_centimetros\", \"INT\", False),\n",
    "    ],\n",
    "    # dm_categoria_produtos_traducao (Etapa 8) \n",
    "    \"dm_categoria_produtos_traducao\": [\n",
    "        (\"product_category_name\", \"nome_produto_pt\", \"STRING\", False),\n",
    "        (\"product_category_name_english\", \"nome_produto_en\", \"STRING\", False),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Execução\n",
    "print(\"Iniciando transformações simples (ft_itens_pedidos, ft_vendedores, ft_produtos, dm_categoria_produtos_traducao)...\")\n",
    "for table_name, mapping in TRANSFORM_MAP.items():\n",
    "    transform_and_save_simple_final(table_name, mapping)\n",
    "print(\"✅ Transformações simples concluídas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fc29c32-a5e5-48c7-984f-81821b39f938",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# silver.ft_avaliacoes_pedidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "335e2451-e2cc-44c7-81ff-d62d8342dbff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Implementa a limpeza de dados (IDs inválidos e datas inconsistentes/futuras) e documenta a contagem de linhas removidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bd444a1-340c-4ac6-ad48-50e245faf439",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Documentação da Limpeza de Avaliações ---\nTotal de linhas em Bronze: 104162\nLinhas removidas por ID/Data inválida: 8854\nTotal final na Silver: 95308\nRegras de Validação Aplicadas: order_id não nulo e com 32 caracteres; datas válidas e não futuras.\n---------------------------------------------\n✅ Tabela Silver 'silver.ft_avaliacoes_pedidos' criada/atualizada com sucesso.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    col, try_to_timestamp, lit, length, current_timestamp, expr, trim\n",
    ")\n",
    "\n",
    "# Definição das tabelas\n",
    "source_table = \"bronze.ft_avaliacoes_pedidos\"\n",
    "target_table = \"silver.ft_avaliacoes_pedidos\"\n",
    "\n",
    "# Lendo a tabela Bronze\n",
    "df_bronze = spark.read.table(source_table)\n",
    "initial_count = df_bronze.count()\n",
    "\n",
    "# Limpeza de dados\n",
    "today_ts_literal = current_timestamp()\n",
    "\n",
    "# Regras de validação:\n",
    "# ID incorreto: nulo OU tamanho diferente de 32 (\n",
    "# Data incorreta: nula, formato inconsistente OU data futura\n",
    "df_valid = (\n",
    "    df_bronze\n",
    "    .withColumn(\"review_creation_date_ts\",\n",
    "        try_to_timestamp(col(\"review_creation_date\"), lit(\"yyyy-MM-dd HH:mm:ss\"))\n",
    "    )\n",
    "    .withColumn(\"review_answer_timestamp_ts\",\n",
    "        try_to_timestamp(col(\"review_answer_timestamp\"), lit(\"yyyy-MM-dd HH:mm:ss\"))\n",
    "    )\n",
    "    .withColumn(\"review_score\", trim(col(\"review_score\")))\n",
    "\n",
    "    .filter(\n",
    "        # 1. Validação de ID [cite: 134]\n",
    "        (col(\"order_id\").isNotNull()) & \n",
    "        (length(col(\"order_id\")) == 32) & \n",
    "        (col(\"review_creation_date_ts\").isNotNull()) & \n",
    "        (col(\"review_creation_date_ts\") < today_ts_literal) \n",
    "    )\n",
    ")\n",
    "\n",
    "# Conversão do score\n",
    "df_valid = df_valid.withColumn(\"review_score_int\", expr(\"try_cast(review_score as int)\"))\n",
    "\n",
    "# Contagem e documentação\n",
    "final_count = df_valid.count()\n",
    "removed_count = initial_count - final_count\n",
    "\n",
    "print(\"--- Documentação da Limpeza de Avaliações ---\")\n",
    "print(f\"Total de linhas em Bronze: {initial_count}\")\n",
    "print(f\"Linhas removidas por ID/Data inválida: {removed_count}\")\n",
    "print(f\"Total final na Silver: {final_count}\")\n",
    "print(f\"Regras de Validação Aplicadas: order_id não nulo e com 32 caracteres; datas válidas e não futuras.\")\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "# Seleção e renomeação\n",
    "df_silver = (\n",
    "    df_valid.select(\n",
    "        col(\"review_id\").alias(\"id_avaliacao\"),\n",
    "        col(\"order_id\").alias(\"id_pedido\"),\n",
    "        col(\"review_score_int\").alias(\"avaliacao\"),\n",
    "        col(\"review_comment_title\").alias(\"titulo_comentario\"),\n",
    "        col(\"review_comment_message\").alias(\"comentario\"),\n",
    "        col(\"review_creation_date_ts\").alias(\"data_comentario\"),\n",
    "        col(\"review_answer_timestamp_ts\").alias(\"data_resposta\"),\n",
    "        col(\"ingestion_timestamp\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Salvar na camada Silver\n",
    "df_silver.write.mode(\"overwrite\").format(\"delta\").saveAsTable(target_table)\n",
    "\n",
    "print(f\"✅ Tabela Silver '{target_table}' criada/atualizada com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65480310-e6f6-4d02-924b-5341f73ab9ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# silver.dm_cotacao_dolar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "403fddf0-ea28-499c-a717-ef76e0e67408",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Utiliza Window Functions do Spark para preencher os valores de cotação nulos de fins de semana com o último valor disponível (da sexta-feira)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f9336ba-f1cd-4024-9e03-ae9815879e32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela Silver 'silver.dm_cotacao_dolar' criada/atualizada com sucesso (com preenchimento de fins de semana).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, last, asc, to_timestamp, round\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import DateType, DecimalType\n",
    "\n",
    "source_table = \"bronze.dm_cotacao_dolar\"\n",
    "target_table = \"silver.dm_cotacao_dolar\"\n",
    "\n",
    "# Pré-processamento e Padronização\n",
    "df_bronze = (spark.read.table(source_table)\n",
    "             .select(\n",
    "                 col(\"cotacaoCompra\").cast(DecimalType(5, 4)).alias(\"cotacao_dolar\"),\n",
    "                 to_timestamp(col(\"dataHoraCotacao\"), \"yyyy-MM-dd HH:mm:ss.SSS\").cast(DateType()).alias(\"data\"), \n",
    "                 col(\"ingestion_timestamp\")\n",
    "             )\n",
    "             .dropDuplicates([\"data\"])\n",
    "            )\n",
    "\n",
    "# 2. Enriquecimento\n",
    "window_spec = Window.partitionBy(lit(1)).orderBy(asc(\"data\")).rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "df_filled = (df_bronze\n",
    "    .withColumn(\"cotacao_dolar_filled\", \n",
    "        last(col(\"cotacao_dolar\"), ignorenulls=True).over(window_spec)\n",
    "    )\n",
    "    .drop(\"cotacao_dolar\")\n",
    "    .withColumnRenamed(\"cotacao_dolar_filled\", \"cotacao_dolar\")\n",
    "    .withColumn(\"cotacao_dolar\", round(col(\"cotacao_dolar\"), 4)) # Arredonda para 4 casas\n",
    ")\n",
    "\n",
    "# 3. Salvar na Camada Silver\n",
    "(df_filled.write\n",
    "    .mode(\"overwrite\")\n",
    "    .format(\"delta\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(target_table))\n",
    "\n",
    "print(f\"✅ Tabela Silver '{target_table}' criada/atualizada com sucesso (com preenchimento de fins de semana).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a141b880-d51a-4935-aad9-674588a3ad1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Validação de Integridade e Remoção de Órfãos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a19b9ff2-ee65-4ef5-9bf2-ec07b1c919e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Realiza o controle de integridade referencial entre as três tabelas principais, utilizando o left_anti join para identificar e remover os registros órfãos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1667ef04-7b0e-4aef-a12c-9893253c4837",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDD22 Total de Pedidos Órfãos (sem Consumidor válido): 0\n\uD83D\uDD22 Total de Itens Órfãos (sem Pedido válido): 0\n\n✅ Verificações de Integridade Concluídas.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# 1. Pedidos Órfãos (Pedidos sem Consumidor válido)\n",
    "df_pedidos = spark.read.table(\"silver.ft_pedidos\")\n",
    "df_consumidores = spark.read.table(\"silver.ft_consumidores\")\n",
    "target_pedidos = \"silver.ft_pedidos\"\n",
    "\n",
    "# Identificar pedidos órfãos (Pedidos em ft_pedidos QUE NÃO EXISTEM em ft_consumidores)\n",
    "df_pedidos_orphans = (df_pedidos\n",
    "    .join(df_consumidores, [\"id_consumidor\"], \"left_anti\") \n",
    ")\n",
    "\n",
    "num_pedidos_orphans = df_pedidos_orphans.count()\n",
    "print(f\"\\n\uD83D\uDD22 Total de Pedidos Órfãos (sem Consumidor válido): {num_pedidos_orphans}\")\n",
    "\n",
    "if num_pedidos_orphans > 0:\n",
    "    df_pedidos_valid = (df_pedidos\n",
    "        .join(df_pedidos_orphans.select(\"id_pedido\"), [\"id_pedido\"], \"left_anti\")\n",
    "    )\n",
    "    df_pedidos_valid.write.mode(\"overwrite\").format(\"delta\").saveAsTable(target_pedidos)\n",
    "    print(f\"  > ✅ Pedidos órfãos removidos de '{target_pedidos}'.\")\n",
    "\n",
    "# 2. Itens Órfãos (Itens sem Pedido válido)\n",
    "df_itens_pedidos = spark.read.table(\"silver.ft_itens_pedidos\")\n",
    "target_itens = \"silver.ft_itens_pedidos\"\n",
    "\n",
    "# Recarrega a tabela de pedidos\n",
    "df_pedidos_reloaded = spark.read.table(\"silver.ft_pedidos\") \n",
    "\n",
    "# Identificar itens órfãos (Itens em ft_itens_pedidos que não existem em ft_pedidos_reloaded)\n",
    "df_itens_orphans = (df_itens_pedidos\n",
    "    .join(df_pedidos_reloaded, [\"id_pedido\"], \"left_anti\")\n",
    ")\n",
    "\n",
    "num_itens_orphans = df_itens_orphans.count()\n",
    "print(f\"\uD83D\uDD22 Total de Itens Órfãos (sem Pedido válido): {num_itens_orphans}\")\n",
    "\n",
    "if num_itens_orphans > 0:\n",
    "    # Remover itens órfãos\n",
    "    df_itens_valid = (df_itens_pedidos\n",
    "        .join(df_itens_orphans.select(\"id_item\"), [\"id_item\"], \"left_anti\")\n",
    "    )\n",
    "    # Sobrescreve a tabela original com apenas os dados válidos\n",
    "    df_itens_valid.write.mode(\"overwrite\").format(\"delta\").saveAsTable(target_itens)\n",
    "    print(f\"  > ✅ Itens órfãos removidos de '{target_itens}'.\")\n",
    "\n",
    "print(\"\\n✅ Verificações de Integridade Concluídas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edacedae-5c9e-4f01-9528-000b59be9a84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Criação da Tabela Final - silver.pedido_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0dc2bef-8c81-4982-8bb2-4647c8d03c62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Agrega os pagamentos, une os dados de pedido e aplica a conversão de BRL para USD usando a cotação diária ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bde7bba-0bbe-4936-b384-455d7e2caec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela Silver FINAL 'silver.pedido_total' criada com sucesso. Processo de ETL concluído.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, date_format, round, max, col\n",
    "\n",
    "target_table = \"silver.pedido_total\"\n",
    "\n",
    "# Carregar as fontes (todas as tabelas são SILVER, exceto ft_pagamentos, que pode ter sido usada antes de silver.ft_pedidos ter órfãos removidos)\n",
    "df_pedidos = spark.read.table(\"silver.ft_pedidos\")\n",
    "df_pagamentos = spark.read.table(\"silver.ft_pagamentos\")\n",
    "df_cotacao = spark.read.table(\"silver.dm_cotacao_dolar\")\n",
    "\n",
    "# Agregação de pagamentos (Valor Total BRL)\n",
    "df_total_pagamento = (df_pagamentos\n",
    "    .groupBy(\"id_pedido\")\n",
    "    .agg(sum(col(\"valor_pagamento\")).alias(\"valor_total_pago_brl\"))\n",
    ")\n",
    "\n",
    "# Preparação da cotação (Uma cotação por dia)\n",
    "df_cotacao_diaria = (df_cotacao\n",
    "    .withColumn(\"data_pedido_str\", date_format(col(\"data\"), \"yyyy-MM-dd\"))\n",
    "    .select(\"data_pedido_str\", \"cotacao_dolar\")\n",
    "    .dropDuplicates([\"data_pedido_str\"]) \n",
    ")\n",
    "\n",
    "# Join e enriquecimento\n",
    "df_final = (df_pedidos\n",
    "    .join(df_total_pagamento, [\"id_pedido\"], \"inner\")\n",
    "    .withColumn(\"data_pedido_str\", date_format(col(\"pedido_compra_timestamp\"), \"yyyy-MM-dd\"))\n",
    "    .join(df_cotacao_diaria, [\"data_pedido_str\"], \"left\")\n",
    "    .withColumn(\"valor_total_pago_usd\", \n",
    "        round(col(\"valor_total_pago_brl\") / col(\"cotacao_dolar\"), 2) \n",
    "    )\n",
    "    .select(\n",
    "        date_format(col(\"pedido_compra_timestamp\"), \"yyyy-MM-dd\").alias(\"data_pedido\"),\n",
    "        col(\"id_pedido\"), \n",
    "        col(\"id_consumidor\"), \n",
    "        col(\"status\"), \n",
    "        col(\"valor_total_pago_brl\"), \n",
    "        col(\"valor_total_pago_usd\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Salvar Tabela Final\n",
    "(df_final.write\n",
    "    .mode(\"overwrite\")\n",
    "    .format(\"delta\")\n",
    "    .saveAsTable(target_table))\n",
    "\n",
    "print(f\"✅ Tabela Silver FINAL '{target_table}' criada com sucesso. Processo de ETL concluído.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cf70941-bc0b-46c9-9cd4-394aaec077b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Verificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2868b7a-6f2a-4b2f-9aeb-bfb1ba978644",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------------------+--------------------------------+--------+--------------------+--------------------+\n|data_pedido|id_pedido                       |id_consumidor                   |status  |valor_total_pago_brl|valor_total_pago_usd|\n+-----------+--------------------------------+--------------------------------+--------+--------------------+--------------------+\n|2017-10-02 |e481f51cbdc54678b7cc49136f2d6af7|9ef432eb6251297304e76186b10a928d|entregue|38.71               |NULL                |\n|2018-07-24 |53cdb2fc8bc7dce0b6741e2150273451|b0830fb4747a6c6d20dea0b8c802d7ef|entregue|141.46              |NULL                |\n|2018-08-08 |47770eb9100c2d0c44946d9cf07ec65d|41ce2a54c0b03bf3443c3d931a367089|entregue|179.12              |NULL                |\n|2017-11-18 |949d5b44dbf5de918fe9c16f97b45f8a|f88197465ea7920adcdbec7375364d82|entregue|72.20               |NULL                |\n|2018-02-13 |ad21c59c0840e6cb83a9ceb5573f8159|8ab97904e6daea8866dbdbc4fb7aad2c|entregue|28.62               |NULL                |\n|2017-07-09 |a4591c265e18cb1dcee52889e2d8acc3|503740e9ca751ccdda7ba28e9ab8f608|entregue|175.26              |NULL                |\n|2017-04-11 |136cce7faa42fdb2cefd53fdc79a6098|ed0271e0b7da060a393796590e7b737a|faturado|65.95               |NULL                |\n|2017-05-16 |6514b8ad8028c9f2cc2374ded245783f|9bdf08b4b3b52b5526ff42d37d47f222|entregue|75.16               |NULL                |\n|2017-01-23 |76c6e866289321a7c93b82b54852dc33|f54a9f0e6b351c431402b8461ea51999|entregue|35.95               |NULL                |\n|2017-07-29 |e69bfb5eb88e0ed6a785585b27e16dbf|31ad1d1b63eb9962463f764d4e6e0c9d|entregue|169.76              |NULL                |\n+-----------+--------------------------------+--------------------------------+--------+--------------------+--------------------+\nonly showing top 10 rows\nroot\n |-- data_pedido: string (nullable = true)\n |-- id_pedido: string (nullable = true)\n |-- id_consumidor: string (nullable = true)\n |-- status: string (nullable = true)\n |-- valor_total_pago_brl: decimal(22,2) (nullable = true)\n |-- valor_total_pago_usd: decimal(27,2) (nullable = true)\n\n+-----------+--------------------------------+--------------------------------+--------+--------------------+--------------------+\n|data_pedido|id_pedido                       |id_consumidor                   |status  |valor_total_pago_brl|valor_total_pago_usd|\n+-----------+--------------------------------+--------------------------------+--------+--------------------+--------------------+\n|2017-10-02 |e481f51cbdc54678b7cc49136f2d6af7|9ef432eb6251297304e76186b10a928d|entregue|38.71               |NULL                |\n|2017-10-02 |03054d8a8eefc2981cfad06f58e27979|9bd2f246e81c19f65c539ce426288ef5|entregue|74.06               |NULL                |\n|2017-10-02 |b4a1c1abe13b0e2adafb21da024cef98|81aef10a9af8f93cbfbf20e884277260|entregue|128.31              |NULL                |\n|2017-10-02 |b22fe8539dd76cacfc5337279db388b9|20091e2dd1dcc3a5a32cec435515a68e|entregue|172.40              |NULL                |\n|2017-10-02 |109ff01cec6b68a8e70ed431552b9be0|43c9df3440bc8c9934f5aabc6a51f0eb|entregue|263.24              |NULL                |\n+-----------+--------------------------------+--------------------------------+--------+--------------------+--------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_final = spark.read.table(\"silver.pedido_total\")\n",
    "\n",
    "# Exibe as primeiras 10 linhas\n",
    "df_final.show(10, truncate=False)\n",
    "\n",
    "# Exibe o schema (para confirmar os tipos de dados)\n",
    "df_final.printSchema()\n",
    "\n",
    "# Para conferir o exemplo de 2017-10-02\n",
    "df_final.filter(col(\"data_pedido\") == \"2017-10-02\").show(5, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Atividade2_bronze_to_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}